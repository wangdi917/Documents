{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText文章中使用的搜狗新闻数据集\n",
    "* Categories\n",
    "  + sports\n",
    "  + finance\n",
    "  + entertainment \n",
    "  + automobile\n",
    "  + technology”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载数据 ，预先处理\n",
    "1. gbk --> utf-8\n",
    "2. 从<url>提取类别标签\n",
    "3. 从<content>提取文本内容\n",
    "\n",
    "参考资料\n",
    "* [word2vec 构建中文词向量](http://www.cnblogs.com/Newsteinwell/p/6034747.html)\n",
    "* [Automatic Online News Issue Construction in Web Environment WWW2008](http://wwwconference.org/www2008/papers/pdf/p457-wang.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2823992it [00:07, 361426.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# 这个实验采用搜狗实验室的搜狗新闻语料库，数据链接\n",
    "# http://www.sogou.com/labs/resource/cs.php\n",
    "# 1-1. 下载下来的文件名为： news_sohusite_xml.full.zip\n",
    "# 1-2. 解压 --> xvf news_sohusite_xml.dat\n",
    "# 1-3.A 字符编码转换  cat news_sohusite_xml.dat | iconv -f gbk -t utf-8 -c | grep \"<content>\\|<url>\"  \n",
    "# > corpus_labeled.txt\n",
    "# 1-3.B 使用codec module读入gbk编码的原始文档，使用unicode或者编码为utf-8\n",
    "\n",
    "file_raw_path = 'data/corpus_labeled.txt'\n",
    "\n",
    "label_raw = []\n",
    "data_raw = []\n",
    "i = 0\n",
    "with open(file_raw_path, encoding='utf-8') as fr:\n",
    "    for line in tqdm(fr):\n",
    "        if i%2==0:\n",
    "            label_raw.append(line[5:-6])\n",
    "        else:\n",
    "            data_raw.append(line[9:-11])\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个样本有一个url，从中我们可以提取一个话题标签\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://gongyi.sohu.com/2012070',\n",
       " 'http://roll.sohu.com/20120625/',\n",
       " 'http://pic.yule.sohu.com/91258',\n",
       " 'http://haodf.health.sohu.com/f',\n",
       " 'http://roll.sohu.com/20120705/',\n",
       " 'http://db.auto.sohu.com/model_',\n",
       " 'http://product.it.sohu.com/sea',\n",
       " 'http://product.it.sohu.com/sea',\n",
       " 'http://dealer.auto.sohu.com/tj',\n",
       " 'http://news.sohu.com/20120726/',\n",
       " 'http://roll.sohu.com/20120706/']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('每一个样本有一个url，从中我们可以提取一个话题标签')\n",
    "\n",
    "[x[:30] for x in label_raw[:len(label_raw):len(label_raw)//10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "统计每个类别的文本数量，对数据有一个初步了解\n",
      "           roll\t\t720957\n",
      "        product\t\t177002\n",
      "           news\t\t70900\n",
      "             db\t\t59043\n",
      "            pic\t\t41236\n",
      "         sports\t\t38281\n",
      "          stock\t\t37126\n",
      "       business\t\t26179\n",
      "         dealer\t\t25663\n",
      "            saa\t\t19671\n",
      "              q\t\t17697\n",
      "           yule\t\t12779\n",
      "           drug\t\t11480\n",
      "          haodf\t\t10890\n",
      "             it\t\t10797\n",
      "           data\t\t9110\n",
      "              s\t\t8678\n",
      "          money\t\t7448\n",
      "          daxue\t\t7021\n",
      "           auto\t\t6843\n"
     ]
    }
   ],
   "source": [
    "print(\"统计每个类别的文本数量，对数据有一个初步了解\")\n",
    "labels = []\n",
    "for label in label_raw:\n",
    "    labels.append(label[7:].split('.')[0])\n",
    "from collections import Counter\n",
    "label_stat = Counter(labels)\n",
    "for k,v in label_stat.most_common(20):\n",
    "    print('%15s\\t\\t%d'%(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据论文`Character Level Convolutional Neural Networks for Text Classification (2015)`的描述，选择下述5类话题的样本\n",
    "1. 'sports'\n",
    "2. 'stock' // finance\n",
    "3. 'yule'  // entertainment \n",
    "4. 'auto'  // automobile\n",
    "5. 'it'    // technology”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义lambda函数 去掉文本中怪异符号，参考自\n",
    "# https://gist.github.com/mrvege/2ba6a437f0a4c4812f21#file-filterpunct-py-L5\n",
    "\n",
    "punct = set(u''':!),.:;?]}¢'\"、。〉》」』】〕〗〞︰︱︳﹐､﹒﹔﹕﹖﹗﹚﹜﹞！），．＊：；Ｏ？｜｝︴︶︸︺︼︾﹀﹂﹄﹏､～￠々‖•·ˇˉ―--′’”([{£¥'\"‵〈《「『【〔〖（［｛￡￥〝︵︷︹︻︽︿﹁﹃﹙﹛﹝（｛“‘-—_…０１２３４５６７８９''')\n",
    "## 对str/unicode\n",
    "filterpunt = lambda s: ''.join(filter(lambda x: x not in punct, s))\n",
    "## 对list\n",
    "# filterpuntl = lambda l: list(filter(lambda x: x not in punct, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1411996/1411996 [00:09<00:00, 148173.61it/s]\n"
     ]
    }
   ],
   "source": [
    "cat_selected = set(['sports', 'stock', 'yule', 'auto', 'it'])\n",
    "label_selected = []\n",
    "content_selected = []\n",
    "for i in tqdm(range(len(labels))):\n",
    "    if labels[i] in cat_selected and len(data_raw[i])>10:\n",
    "        label_selected.append(labels[i])\n",
    "        content_selected.append(filterpunt(data_raw[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus样本\n",
      "\n",
      "example 0 \n",
      "\tstock\n",
      "\t注每次查询最多显示条\n",
      "\n",
      "example 1234 \n",
      "\tsports\n",
      "\t北京时间月日欧洲杯Ｄ组末轮一场比赛在顿涅茨克顿巴斯竞技场展开争夺英格兰客场比力克乌克兰解禁复出的鲁尼打入全场唯一入球英格兰胜平不败战绩获得小组头名决赛将对阵意大利ｓｐｏｒｔｓ全体育图片社Ｖ行峦月日电　据英国每日邮报报道财大气粗的巴黎圣日耳曼队正密谋以万英镑的价格引进切尔西队长约翰特里巴黎圣日耳曼主帅安切洛蒂曾和特里共事一年日前他本想以万英镑的天价引进ＡＣ米兰后卫蒂亚戈席尔瓦但这桩交易在最后一刻宣布告吹豢ㄋ尔财团注资后的巴黎圣日耳曼队并不在乎花钱他们有望以万英镑的价格引进那不勒斯队射手拉维奇而为了得到特里他们准备承诺一份价值万英镑周薪的天价待遇\n",
      "\n",
      "example 2468 \n",
      "\tstock\n",
      "\t全景网月日讯　钢铁板块周一早盘走弱ＳＴ广钢跌逾％鲁银投资大金重工等多只个股跌逾％因钢铁行业经营状况继续恶化＞荨毒济参考报记者从中钢协权威人士处获悉纳入钢协统计的大中型钢铁企业中月份盈利情况再度滑至负数其中利润收入为－亿元月度销售利润率为－％全景网／刘磊\n",
      "\n",
      "example 3702 \n",
      "\tstock\n",
      "\t刘鸿儒开荒修路人苫上拯救股市墒谢挂不要搞　年月深圳和珠海特区成立周年大庆江泽民总书记在深圳了解了股票市场的情况后回头对一起出席的刘鸿儒说返京途中一起就股市的问题聊一聊在返京的飞机上江泽民总书记在刘鸿儒聊了两个多小时最终江泽民总书记被说服了临下飞机前江泽民对刘鸿儒说股票市场的试点应该保留下来继续试验暂不扩大就这样中国的股票市场算是度过了一次劫难　阅读全文］鹕娇谏系闹飨笔绷鹾枞灞恢扉F基找去谈话刘鸿儒说我这是火山口的工作不好做也做不长朱镕基回答说责任不要你承担我来承担刘鸿儒回答说出了事情哪有让总理承担的当然有我来承担就这样刘鸿儒租了保利大厦的两层楼作为办公室拿着借来的办公经费开始了第一届证监会的工作　阅读全文］＠肴魏蟮摹傲跬贰饼Ｔ诘Ｈ沃ぜ嗷嶂飨的这段时间刘鸿儒获得了同事一个充满情意的绰号刘头年刘头从证监会主席的位置离任开始了他证券人生的另外的辉煌生涯只不过刘鸿儒不再以监管者的身份在哪里摇旗呐喊而是更像一个学者前辈一样呵护中国的资本市场作为一个学者型的官员刘鸿儒一直坚持对证券市场的理论研究与总结　阅读全文］\n",
      "\n",
      "example 4936 \n",
      "\tsports\n",
      "\t海东青海年月日　体育网球ＩＴＦ国际网球女子巡回赛青海互助站半决赛赛况　月日郭露在比赛中回球当日在ＩＴＦ国际网球女子巡回赛青海互助站比赛中中国选手郭露以比不敌同胞文欣无缘决赛　新华社记者王博摄\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('corpus样本\\n')\n",
    "for i in range(0, 5000, 1234):\n",
    "    print('example %d \\n\\t%s\\n\\t%s\\n' % (i, label_selected[i], content_selected[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/96867 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jieba分词，非常费时:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.733 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "100%|██████████| 96867/96867 [03:18<00:00, 488.29it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"jieba分词，非常费时:\\n\")\n",
    "data_words = []\n",
    "for line in tqdm(content_selected):\n",
    "    data_words.append([' '.join(jieba.cut(line, cut_all=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 0\n",
      "注 每次 查询 最 多 显示 条\n",
      "sentence 1234\n",
      "北京 时间 月 日 欧洲杯 Ｄ 组末 轮 一场 比赛 在 顿涅茨克 顿巴斯 竞技场 展开 争夺 英格兰 客场 比 力克 乌克兰 解禁 复出 的 鲁尼 打入 全场 唯一 入球 英格兰 胜平 不败 战绩 获得 小组 头名 决赛 将 对阵 意大利 ｓ ｐ ｏ ｒ ｔ ｓ 全 体育 图片社 Ｖ 行峦 月 日电 　 据 英国 每日 邮报 报道 财大气粗 的 巴黎 圣日耳曼 队正 密谋 以 万英镑 的 价格 引进 切尔西队 长 约翰 特里 巴黎 圣日耳曼 主帅 安切洛蒂 曾 和 特里 共事 一年 日前 他本 想 以 万英镑 的 天价 引进 Ａ Ｃ 米兰 后卫 蒂 亚戈 席尔瓦 但 这桩 交易 在 最后 一刻 宣布 告吹 豢 ㄋ 尔 财团 注资 后 的 巴黎 圣日耳曼 队 并 不在乎 花钱 他们 有望 以 万英镑 的 价格 引进 那不勒斯 队 射手 拉 维奇 而 为了 得到 特里 他们 准备 承诺 一份 价值 万英镑 周薪 的 天价 待遇\n",
      "sentence 2468\n",
      "全景网 月 日 讯 　 钢铁 板块 周 一早 盘 走 弱 Ｓ Ｔ 广钢 跌 逾 ％ 鲁银投资 大 金 重工 等 多只 个股 跌 逾 ％ 因 钢铁行业 经营 状况 继续 恶化 ＞ 荨毒济 参考报 记者 从中 钢协 权威人士 处 获悉 纳入 钢协 统计 的 大中型 钢铁企业 中 月份 盈利 情况 再度 滑至 负数 其中 利润 收入 为 － 亿元 月度 销售 利润率 为 － ％ 全景网 ／ 刘磊\n",
      "sentence 3702\n",
      "刘鸿儒 开荒 修路 人 苫 上 拯救 股市 墒 谢挂 不要 搞 　 年 月 深圳 和 珠海 特区 成立 周年 大庆 江泽民 总书记 在 深圳 了解 了 股票市场 的 情况 后 回头 对 一起 出席 的 刘鸿儒 说 返京 途中 一起 就 股市 的 问题 聊一聊 在 返京 的 飞机 上 江泽民 总书记 在 刘鸿儒 聊 了 两个 多 小时 最终 江泽民 总书记 被 说服 了 临下 飞机 前 江泽民 对 刘鸿儒 说 股票市场 的 试点 应该 保留 下来 继续 试验 暂 不 扩大 就 这样 中国 的 股票市场 算是 度过 了 一次 劫难 　 阅读 全文 ］ 鹕 娇谏 系闹 飨 笔 绷 鹾 枞 灞 恢扉 F 基找 去 谈话 刘鸿儒 说 我 这 是 火山口 的 工作 不好 做 也 做 不长 朱镕基 回答 说 责任 不要 你 承担 我来 承担 刘鸿儒 回答 说出 了 事情 哪有 让 总理 承担 的 当然 有 我 来 承担 就 这样 刘鸿儒 租 了 保利大厦 的 两层楼 作为 办公室 拿 着 借来 的 办公 经费 开始 了 第一届 证监会 的 工作 　 阅读 全文 ］ ＠ 肴 魏 蟮 摹傲 跬 贰 饼 Ｔ 诘 Ｈ 沃 ぜ 嗷 嶂 飨 的 这 段时间 刘鸿儒 获得 了 同事 一个 充满 情意 的 绰号 刘头 年 刘头 从 证监会 主席 的 位置 离任 开始 了 他 证券 人生 的 另外 的 辉煌 生涯 只不过 刘鸿儒 不再 以 监管者 的 身份 在 哪里 摇旗呐喊 而是 更 像 一个 学者 前辈 一样 呵护 中国 的 资本 市场 作为 一个 学者型 的 官员 刘鸿儒 一直 坚持 对 证券市场 的 理论 研究 与 总结 　 阅读 全文 ］\n",
      "sentence 4936\n",
      "海东青 海 年月日 　 体育 网球 Ｉ Ｔ Ｆ 国际 网球 女子 巡回赛 青海 互助 站 半决赛 赛况 　 月 日 郭露 在 比赛 中 回球 当日 在 Ｉ Ｔ Ｆ 国际 网球 女子 巡回赛 青海 互助 站 比赛 中 中国 选手 郭露 以 比 不 敌 同胞 文欣 无缘 决赛 　 新华社 记者 王博摄\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5000, 1234):\n",
    "    print('sentence %d' % i)\n",
    "    print(' '.join(data_words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "with open('data/sogou_news_test.txt', 'w') as f:\n",
    "    for i in range(len(data_words)):\n",
    "        if i%5==0:\n",
    "            s = '__label__' + label_selected[i] + ' '\n",
    "            s = s + \" \".join([x for x in data_words[i]])\n",
    "            f.write(s)\n",
    "            f.write('\\n')\n",
    "\n",
    "with open('data/sogou_news_train.txt', 'w') as f:\n",
    "    for i in range(len(data_words)):\n",
    "        if i%5!=0:\n",
    "            s = '__label__' + label_selected[i] + ' '\n",
    "            s = s + \" \".join([x for x in data_words[i]])\n",
    "            f.write(s)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-579b504c5e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                  \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                  \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                  epoch = 50)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mresult_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/sogou_news_test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfasttext/fasttext.pyx\u001b[0m in \u001b[0;36mfasttext.fasttext.supervised (fasttext/fasttext.cpp:7265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfasttext/fasttext.pyx\u001b[0m in \u001b[0;36mfasttext.fasttext.train_wrapper (fasttext/fasttext.cpp:6038)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfasttext/fasttext.pyx\u001b[0m in \u001b[0;36mfasttext.fasttext.load_model (fasttext/fasttext.cpp:4078)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/dong/anaconda3/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# This follows symbolic links, so both islink() and isdir() can be true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# for the same path on systems that support symlinks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.05\n",
    "dim = 256\n",
    "\n",
    "classifier = fasttext.supervised(input_file = 'data/sogou_news_train.txt',\n",
    "                                 output = 'data/intent_model',\n",
    "                                 label_prefix = '__label__',\n",
    "                                 dim = dim,\n",
    "                                 lr = lr,\n",
    "                                 epoch = 5)\n",
    "result_tr = classifier.test('data/sogou_news_test.txt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
