{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验演示：对文本数据集作非负矩阵分解 (NMF) 提取话题(topic) 信息\n",
    "\n",
    "### 话题(topic)是一种粗略地描述语义(semantic)的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/NMF.png)\n",
    "\n",
    "**一个2个话题，4个单词，6篇文本的数据集的非负矩阵分集示意图**\n",
    "\n",
    "* **V**: term-document matrix, `V[i][j]` 表示文本j里面词语i出现的频率\n",
    "* **W**: term-topic matrix， `W[i][j]` 表示单词i和话题j的密切程度\n",
    "* **H**: topic-document matrix， `H[i][j]`表示文本j里面话题i的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    \"\"\"打印每个话题里面\"n_top_words\"个最常见的词语\n",
    "    \"\"\"\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\", \".join([feature_names[i]\n",
    "                         for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取数据 ...\n",
      "完成，共耗时 1.261 秒.\n",
      "共有11314篇文本， 我们使用其中2000做实验演示\n"
     ]
    }
   ],
   "source": [
    "# 获取 20newsgroups 数据集\n",
    "print(\"读取数据 ...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "print(\"完成，共耗时 %0.3f 秒.\" % (time() - t0))\n",
    "\n",
    "n_samples = 2000\n",
    "print(\"共有%d篇文本， 我们使用其中%d做实验演示\" % (len(dataset['data']), n_samples))\n",
    "data_samples = dataset.data[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well i'm not sure about the story nad it did seem biased. WhatI disagree with is your statement that the U.S. Media is out toruin Israels reputation. That is rediculous. The U.S. media isthe most pro-israeli media in the world. Having lived in EuropeI realize that incidences such as the one described in theletter have occured. The U.S. media as a whole seem to try toignore them. The U.S. is subsidizing Israels existance and theEuropeans are not (at least not to the same degree). So I thinkthat might be a reason they report more clearly on theatrocities.\tWhat is a shame is that in Austria, daily reports ofthe inhuman acts commited by Israeli soldiers and the blessingreceived from the Government makes some of the Holocaust guiltgo away. After all, look how the Jews are treating other raceswhen they got power. It is unfortunate.\n",
      "\n",
      "Yeah, do you expect people to read the FAQ, etc. and actually accept hardatheism?  No, you need a little leap of faith, Jimmy.  Your logic runs outof steam!Jim,Sorry I can't pity you, Jim.  And I'm sorry that you have these feelings ofdenial about the faith you need to get by.  Oh well, just pretend that it willall end happily ever after anyway.  Maybe if you start a new newsgroup,alt.atheist.hard, you won't be bummin' so much?Bye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) --Bake Timmons, III\n",
      "\n",
      "Although I realize that principle is not one of your strongestpoints, I would still like to know why do do not ask any questionof this sort about the Arab countries.   If you want to continue this think tank charade of yours, yourfixation on Israel must stop.  You might have to start asking thesame sort of questions of Arab countries as well.  You realize itwould not work, as the Arab countries' treatment of Jews over thelast several decades is so bad that your fixation on Israel wouldbegin to look like the biased attack that it is.   Everyone in this group recognizes that your stupid 'Center forPolicy Research' is nothing more than a fancy name for some bigotwho hates Israel.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 打印几篇样本\n",
    "for i in range(3):\n",
    "    print(\"%s\\n\" % dataset['data'][i].replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/nmf_bow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在提取文本的 tf-idf 特征 ...\n",
      "完成，共耗时 0.296 秒.\n"
     ]
    }
   ],
   "source": [
    "n_features = 1000\n",
    "\n",
    "print(\"正在提取文本的 tf-idf 特征 ...\")\n",
    "\n",
    "# 计算文本的tf-idf作为输入NMF模型的特征（feature）.\n",
    "# 1max_df=0.95, min_df=2： 使用一些启发式(heuristic)规则预处理去掉一些词语,\n",
    "#   删除只在一个文本中出现或者在95%以上的文本中出现的词语\n",
    "# max_features=n_features: 预处理后，在剩余的词语里面保留数据集中最常见的n_feature个词语\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"完成，共耗时 %0.3f 秒.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000篇文本数据集的 bag-of-word 表示:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2000篇文本数据集的 bag-of-word 表示:\")\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学习 NMF 分解来拟合 tfidf 特征矩阵, NMF使用10个话题（topics）...\n",
      "完成，共耗时 0.934 秒.\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "n_topics = 10\n",
    "print(\"学习 NMF 分解来拟合 tfidf 特征矩阵, NMF使用%d个话题（topics）...\"\n",
    "      % (n_topics))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"完成，共耗时 %0.3f 秒.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习模型两个基本部分:结构和参数\n",
    "### 1. 人为定义的结构（例如tensorflow实现时候的computational graph)\n",
    "### 2. 模型自己学习到的知识，保存在参数中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nmf模型对文本的理解保存在nmf.components_参数矩阵中\n",
    "\n",
    "nmf.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 来定性理解下NMF参数中的语义信息\n",
    "\n",
    "### 1. 首先看看每个话题下面的重要词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "每个话题的代表词语有:\n",
      "Topic #0:\n",
      "just, people, don, think, like, know, time, good, make, way\n",
      "Topic #1:\n",
      "windows, use, dos, using, window, program, os, drivers, application, help\n",
      "Topic #2:\n",
      "god, jesus, bible, faith, christian, christ, christians, does, heaven, sin\n",
      "Topic #3:\n",
      "thanks, know, does, mail, advance, hi, info, interested, email, anybody\n",
      "Topic #4:\n",
      "car, cars, tires, miles, 00, new, engine, insurance, price, condition\n",
      "Topic #5:\n",
      "edu, soon, com, send, university, internet, mit, ftp, mail, cc\n",
      "Topic #6:\n",
      "file, problem, files, format, win, sound, ftp, pub, read, save\n",
      "Topic #7:\n",
      "game, team, games, year, win, play, season, players, nhl, runs\n",
      "Topic #8:\n",
      "drive, drives, hard, disk, floppy, software, card, mac, computer, power\n",
      "Topic #9:\n",
      "key, chip, clipper, keys, encryption, government, public, use, secure, enforcement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n每个话题的代表词语有:\")\n",
    "n_top_words = 10\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 然后看看一些单词的话题归属"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id = [None]*4\n",
    "id[0] = tfidf_feature_names.index('software')\n",
    "id[1] = tfidf_feature_names.index('computer')\n",
    "id[2] = tfidf_feature_names.index('faith')\n",
    "id[3] = tfidf_feature_names.index('bible')\n",
    "\n",
    "xs = [None]*4\n",
    "for i in range(4):\n",
    "    xs[i] = nmf.components_[:,id[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "四个单词在话题空间的坐标/表示(representation)/特征(feature)\n",
      "\n",
      "每个单词是一个10维的词向量:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03246496,  0.09201278,  0.02325284,  0.05181221],\n",
       "       [ 0.26150334,  0.05643936,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.30131641,  0.42290532],\n",
       "       [ 0.01995936,  0.01684022,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.01892334,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.31628097,  0.20540135,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.00533712,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"四个单词在话题空间的坐标/表示(representation)/特征(feature)\\n\")\n",
    "\n",
    "print(\"每个单词是一个%d维的词向量:\" % (n_topics))\n",
    "\n",
    "np.array(xs).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
